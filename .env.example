# BiTranslator environment variable configuration
# Copy this file to .env and fill in your configuration

# LLM provider: "openai", "gemini", or "ollama"
BT_LLM_PROVIDER=openai

# API Key (OpenAI or compatible API)
BT_LLM_API_KEY=sk-your-key-here

# API Base URL
# OpenAI: https://api.openai.com/v1
# Gemini: https://generativelanguage.googleapis.com/v1beta/openai/
# DeepSeek: https://api.deepseek.com/v1
# Local Ollama: http://localhost:11434/v1
BT_LLM_BASE_URL=https://api.openai.com/v1

# Model for analysis
BT_LLM_MODEL=gpt-4o

# Model for translation (leave empty to use analysis model)
BT_TRANSLATION_MODEL=

# Temperature (0-2, 0.3 recommended for translation)
BT_LLM_TEMPERATURE=0.3

# Maximum characters per translation chunk
BT_MAX_CHAPTER_CHARS=12000
